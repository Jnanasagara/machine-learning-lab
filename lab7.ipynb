{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNMkPNnSLgSpUJ1QRcvEl1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jnanasagara/machine-learning-lab/blob/main/lab7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPcgItpfwhlX",
        "outputId": "4752473c-956b-4e37-d4f4-a3beea10b643"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCk3ZJSlwett",
        "outputId": "6d2ef043-e688-4515-9d8b-8f359a0f6743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Multiple Classifier Comparison ===\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "\n",
            "Best Random Forest Parameters: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': None, 'bootstrap': False}\n",
            "Best Cross-Validation Score: 1.0\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "Training Decision Tree...\n",
            "\n",
            "Training Random Forest...\n",
            "\n",
            "Training AdaBoost...\n",
            "\n",
            "Training XGBoost...\n",
            "\n",
            "Training Naive Bayes...\n",
            "\n",
            "Training MLP...\n",
            "\n",
            "Classification Results:\n",
            "   Classifier  Train Accuracy  Test Accuracy  Precision   Recall  F1-Score  CV Mean Accuracy\n",
            "          SVM         1.00000       0.999678   0.999678 0.999678  0.999678               NaN\n",
            "Decision Tree         1.00000       1.000000   1.000000 1.000000  1.000000               NaN\n",
            "Random Forest         1.00000       1.000000   1.000000 1.000000  1.000000               1.0\n",
            "     AdaBoost         1.00000       1.000000   1.000000 1.000000  1.000000               NaN\n",
            "      XGBoost         1.00000       1.000000   1.000000 1.000000  1.000000               NaN\n",
            "  Naive Bayes         0.99124       0.990504   0.990634 0.990504  0.990465               NaN\n",
            "          MLP         1.00000       0.999678   0.999678 0.999678  0.999678               NaN\n",
            "\n",
            "Best Model: Decision Tree\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1979\n",
            "           1       1.00      1.00      1.00      4234\n",
            "\n",
            "    accuracy                           1.00      6213\n",
            "   macro avg       1.00      1.00      1.00      6213\n",
            "weighted avg       1.00      1.00      1.00      6213\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Optional CatBoost import\n",
        "try:\n",
        "    from catboost import CatBoostClassifier\n",
        "    catboost_available = True\n",
        "except ImportError:\n",
        "    catboost_available = False\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "csv_path = '/content/drive/MyDrive/ml-stuttering-events-dataset/cleaned-sep28k.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "X = df.drop('Stuttering', axis=1)\n",
        "y = df['Stuttering']\n",
        "\n",
        "# Encode target if not numeric\n",
        "if not np.issubdtype(y.dtype, np.number):\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "# Multiple Classifier Comparison\n",
        "\n",
        "print(\"\\n=== Multiple Classifier Comparison ===\")\n",
        "\n",
        "# Train-test split for full feature set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X.drop(columns=['0_binned','1_binned'], errors='ignore'),\n",
        "    y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# RandomizedSearchCV for Random Forest\n",
        "param_dist = {\n",
        "    \"n_estimators\": [50, 100, 200],\n",
        "    \"max_depth\": [3, 5, 10, None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "    \"bootstrap\": [True, False]\n",
        "}\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf_random = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=10, cv=5, verbose=1, n_jobs=-1, random_state=42)\n",
        "rf_random.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest Random Forest Parameters:\", rf_random.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", rf_random.best_score_)\n",
        "\n",
        "# Multiple classifiers\n",
        "classifiers = {\n",
        "    \"SVM\": make_pipeline(StandardScaler(), SVC(kernel='rbf', probability=True, random_state=42)),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": rf_random.best_estimator_,\n",
        "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"MLP\": make_pipeline(StandardScaler(), MLPClassifier(max_iter=200, random_state=42))\n",
        "}\n",
        "if catboost_available:\n",
        "    classifiers[\"CatBoost\"] = CatBoostClassifier(verbose=0, random_state=42)\n",
        "\n",
        "results = []\n",
        "for name, model in classifiers.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    train_acc = accuracy_score(y_train, y_pred_train)\n",
        "    test_acc = accuracy_score(y_test, y_pred_test)\n",
        "    precision = precision_score(y_test, y_pred_test, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred_test, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred_test, average='weighted', zero_division=0)\n",
        "\n",
        "    cv_score = rf_random.best_score_ if name == \"Random Forest\" else np.nan\n",
        "    results.append([name, train_acc, test_acc, precision, recall, f1, cv_score])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\n",
        "    \"Classifier\",\"Train Accuracy\",\"Test Accuracy\",\"Precision\",\"Recall\",\"F1-Score\",\"CV Mean Accuracy\"\n",
        "])\n",
        "print(\"\\nClassification Results:\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "best_row = results_df.sort_values(\"Test Accuracy\", ascending=False).iloc[0]\n",
        "best_model_name = best_row[\"Classifier\"]\n",
        "best_model = classifiers[best_model_name]\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, best_model.predict(X_test)))"
      ]
    }
  ]
}